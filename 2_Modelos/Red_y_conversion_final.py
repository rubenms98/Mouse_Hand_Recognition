# -*- coding: utf-8 -*-
"""Red_Y_Conversion_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vzpKfxTcA0nG7nWhhZbZRl3Zhro2N4gJ
"""

from google.colab import files

import tensorflow as tf

from keras import *
from keras.models import Sequential
from keras.layers import Dense
from keras.models import model_from_json
from sklearn.metrics import accuracy_score

import os
import numpy as np
import pandas as pd

import matplotlib
import matplotlib.pyplot as plt

#Install xxd if it is not available
!apt-get -qq install xxd

#Subimos el archivo de nuestro ordenador a Google Colab
#El archivo que vamos a subir es Datos_Posiciones.txt

uploaded = files.upload()

def get_file_size(file_path):
    size = os.path.getsize(file_path)
    return size

def convert_bytes(size, unit=None):
    if unit == "KB":
        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')
    elif unit == "MB":
        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')
    else:
        return print('File size: ' + str(size) + ' bytes')

"""####**TRATAMIENTO DE LOS DATOS**"""

#Vamos a obtener los datos del fichero .txt y los vamos a pasar a una matriz
#Tener cuidado con la ultima fila del archivo subido, si es un espacio en blanco
#dara problemas

file_name = 'Input_Final_NN.txt'

data = uploaded[file_name].decode("utf-8").split("\r\n")

columnas = 16

for i in range(len(data)):
  data[i] = np.array(data[i].split("  "))

data_matrix = np.zeros((len(data), columnas), dtype="float32")

for i in range(len(data)-1):
  for j in range(columnas):
    data_matrix[i][j] = data[i][j].astype(np.float32)

#Con la matriz de la celda anterior vamos a obtener dos matrices
#Matriz con las posiciones: entradas de la red neuronal
#Matriz con las etiquetas de cada posicion: salidas de la red neuronal

np.random.shuffle(data_matrix)

input = np.zeros((len(data), 7))
input = data_matrix[:,:7]
train_position = input[:int(len(input)*0.77),:]
test_position = input[int(len(input)*0.77):,:]

output = np.zeros((len(data), 9))
output = data_matrix[:,7:]
train_labels = output[:int(len(output)*0.77),:]
test_labels = output[int(len(output)*0.77):,:]

"""###**CONSTRUCCIÓN Y COMPILADO DEL MODELO**"""

#Creamos la arquitectura de nuestra red neuronal

nn = [7, 600, 600, 9]  # número de neuronas por capa

model = Sequential(
    [
      
        layers.Dense(nn[1], input_dim=nn[0], activation = 'relu', name = "HiddenLayer1"),
        layers.Dense(nn[2], input_dim=nn[0], activation = 'relu', name = "HiddenLayer2"),
        #layers.Dense(nn[3], input_dim=nn[0], activation = 'relu', name = "HiddenLayer3"),
        #layers.Dense(nn[4], input_dim=nn[0], activation = 'relu', name = "HiddenLayer4"),
        layers.Dense(nn[3], activation = 'sigmoid',  name = "OutputLayer"),
    ]
)

model.summary() #resumen de la arquitectura de la red

class MyThresholdCallback(tf.keras.callbacks.Callback):
    def __init__(self, threshold):
        super(MyThresholdCallback, self).__init__()
        self.threshold = threshold

    def on_epoch_end(self, epoch, logs=None): 
        val_acc = logs["accuracy"]
        if val_acc >= self.threshold:
            self.model.stop_training = True

model.compile(loss = 'binary_crossentropy',
              optimizer = optimizers.Adam(learning_rate = 1e-7),
               metrics = ['accuracy'])

my_callback = MyThresholdCallback(threshold = 0.94)

entrenamiento = model.fit(train_position, train_labels,
                validation_split = 0.20, 
                epochs = 1000,
                callbacks = [my_callback],
                #verbose = 0
                )

MODEL_NAME = "Hand_Recognition.h5"
model.save(MODEL_NAME)

"""###**RESULTADOS DEL ENTRENAMIENTO**"""

test_loss, test_acc = model.evaluate(test_position,  test_labels, verbose=2)
print('\nTest accuracy:', test_acc)

convert_bytes(get_file_size(MODEL_NAME), "MB")

prediccion = model.predict(test_position)

#Guardar en variables los paramtetros de entrenamiento de la red
acc_train = entrenamiento.history['accuracy']
acc_test = entrenamiento.history['val_accuracy']

loss_train = entrenamiento.history['loss']
loss_test = entrenamiento.history['val_loss']

weights_list = model.get_weights()

plt.title('Model accuracy')
plt.plot(acc_train, color = 'orange', label = 'train')
plt.plot(acc_test, color = 'green', label = 'test')
plt.legend(['test', 'train'], loc='lower right')
plt.xlabel('Epochs', labelpad = 7)
plt.ylabel('Accuracy', labelpad = 15)

plt.title('Model loss')
plt.plot(loss_train, color = 'orange', label = 'train')
plt.plot(loss_test, color = 'green', label = 'test')
plt.legend(['test', 'train'], loc='upper right')
plt.xlabel('Epochs', labelpad = 7)
plt.ylabel('Loss', labelpad = 15)

"""###**MODELO SIN OPTIMIZAR**"""

TF_LITE_MODEL_WITHOUT_OPT = "Hand_Recognition_Without_Opt.tflite"

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model_without_optimization = converter.convert()

tflite_model_without_opt_name = TF_LITE_MODEL_WITHOUT_OPT
open(tflite_model_without_opt_name, "wb").write(tflite_model_without_optimization)

interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_WITHOUT_OPT)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("Input Shape:", input_details[0]['shape'])
print("Input Type:", input_details[0]['dtype'])
print("Output Shape:", output_details[0]['shape'])
print("Output Type:", output_details[0]['dtype'])

interpreter.resize_tensor_input(input_details[0]['index'], (len(test_position), 7))
interpreter.resize_tensor_input(output_details[0]['index'], (len(test_labels), 9))
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("Input Shape:", input_details[0]['shape'])
print("Input Type:", input_details[0]['dtype'])
print("Output Shape:", output_details[0]['shape'])
print("Output Type:", output_details[0]['dtype'])

interpreter.set_tensor(input_details[0]['index'], test_position)
interpreter.invoke()
tflite_model_predictions_without_opt = interpreter.get_tensor(output_details[0]['index'])
print("Prediction results shape:", tflite_model_predictions_without_opt.shape)
prediction_classes_without_opt = np.round(tflite_model_predictions_without_opt)

tflite_model_predictions_without_opt_aux = np.zeros((tflite_model_predictions_without_opt.shape[0], tflite_model_predictions_without_opt.shape[1]))

for i in range(tflite_model_predictions_without_opt.shape[0]):
  pos_maximo_brazo = np.argmax(tflite_model_predictions_without_opt[i,:5])
  pos_maximo_dedos = np.argmax(tflite_model_predictions_without_opt[i,5:])
  for j in range(tflite_model_predictions_without_opt.shape[1]):
    if(j < 5 and j == pos_maximo_brazo):
      tflite_model_predictions_without_opt_aux[i][j] = 1
    elif (j >= 5 and j == (pos_maximo_dedos + 5)):
      tflite_model_predictions_without_opt_aux[i][j] = 1

tf_lite_acc = accuracy_score(tflite_model_predictions_without_opt_aux, test_labels)
print('Test accuracy TFLITE model :', tf_lite_acc)

convert_bytes(get_file_size(TF_LITE_MODEL_WITHOUT_OPT), "MB")

"""###**MODELO OPTIMIZADO**"""

TF_LITE_MODEL_OPT = "Hand_Recognition_OPT.tflite"

representative_dataset_size = 500
representative_data= np.zeros((representative_dataset_size, 7), dtype="float32")

for i in range(representative_dataset_size):
  for j in range(7):
    representative_data[i][j] = test_position[i][j].astype(np.float32)

def representative_data_gen():
  for i in range(representative_dataset_size):
    yield[np.array(representative_data, dtype = 'float32', ndmin = 16)]

tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)
tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]

tf_lite_converter.representative_dataset = representative_data_gen
tf_lite_model_optimized = tf_lite_converter.convert()

tflite_model_name = TF_LITE_MODEL_OPT
open(tflite_model_name, "wb").write(tf_lite_model_optimized)

interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_OPT)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("Input Shape:", input_details[0]['shape'])
print("Input Type:", input_details[0]['dtype'])
print("Output Shape:", output_details[0]['shape'])
print("Output Type:", output_details[0]['dtype'])

interpreter.resize_tensor_input(input_details[0]['index'], (len(test_position), 7))
interpreter.resize_tensor_input(output_details[0]['index'], (len(test_labels), 9))
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("Input Shape:", input_details[0]['shape'])
print("Input Type:", input_details[0]['dtype'])
print("Output Shape:", output_details[0]['shape'])
print("Output Type:", output_details[0]['dtype'])

interpreter.set_tensor(input_details[0]['index'], test_position)
interpreter.invoke()
tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])
print("Prediction results shape:", tflite_model_predictions.shape)
prediction_classes = np.round(tflite_model_predictions)

tflite_model_predictions_aux = np.zeros((tflite_model_predictions.shape[0], tflite_model_predictions.shape[1]))

for i in range(tflite_model_predictions.shape[0]):
  pos_maximo_brazo = np.argmax(tflite_model_predictions[i,:5])
  pos_maximo_dedos = np.argmax(tflite_model_predictions[i,5:])
  for j in range(tflite_model_predictions.shape[1]):
    if(j < 5 and j == pos_maximo_brazo):
      tflite_model_predictions_aux[i][j] = 1
    elif (j >= 5 and j == (pos_maximo_dedos + 5)):
      tflite_model_predictions_aux[i][j] = 1

tf_lite_acc = accuracy_score(tflite_model_predictions_aux, test_labels)
print('Test accuracy TFLITE model :', tf_lite_acc)

convert_bytes(get_file_size(TF_LITE_MODEL_OPT), "MB")

"""###**DESCARGA DE LOS MODELOS**"""

# Save the file as a C source file
!xxd -i Hand_Recognition_OPT.tflite > Complete_Hand_NN.cc
# Print the source file
#!cat Hand_Recognition_NN.cc

files.download('Hand_Recognition.h5')
files.download('Hand_Recognition_OPT.tflite')
files.download('Hand_Recognition_Without_Opt.tflite')
files.download('Complete_Hand_NN.cc')